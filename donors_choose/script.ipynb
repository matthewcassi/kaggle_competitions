{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9678b510-3a40-4f36-9d4c-34e6a8dc9670",
    "_uuid": "84b6e37c36b4d1c56fba09c6cf1fdb1a9894c821"
   },
   "source": [
    "# ABC's of Natural Language Processing Machine Learning <br>\n",
    "## Beginners Guide  - Teacher Funding Applications Playground - [DonorChoose.org](https://www.donorschoose.org/)\n",
    "_By Nick Brooks, March 2018_\n",
    "\n",
    "## Table of Content:\n",
    "1. **Feature Engineering:**\n",
    "    - Extracting information from Resource Dataset\n",
    "    - Hand made features and Sentiment Analysis\n",
    "    - The curious incident of the *\"Date Cutoff\"*\n",
    "    - Time Variables, Gender Variable, Multi-Application Teachers\n",
    "    - Label Encoding, and Dummy Variables\n",
    "    - Multiple TF-IDF: Full Guide\n",
    "2. **Modeling:**\n",
    "    - Train/Validation and DMatrix\n",
    "    - Introduction to Extreme Boosting and its paradigm family\n",
    "    - Hyperparameter Guide\n",
    "    - Model\n",
    "    - Feature Importance\n",
    "    - Tree Graphic\n",
    "\n",
    "***\n",
    "\n",
    "## Resource Dataset and Hand Made Text Feature Engineering\n",
    "\n",
    "**Includes:** <br>\n",
    "- Vader Sentiment Analysis\n",
    "- Eight Hand Made Features\n",
    "\n",
    "**Applied to:** <br>\n",
    "- **\"text\" ** : All essays joined together\n",
    "- **\"project_resource_summary\"**: Variable from main dataset\n",
    "- **\"project_title\"**: Variable from main dataset\n",
    "- **\"description\"**: All descriptions from resource dataset joined together. Also summed the quantity, price, and counted the number of resources requested by teacher.\n",
    "***\n",
    "*Load and Combine Test and Train for Combined Processing:* <Br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "0c33ffd6-0e61-42c3-9bf9-def3aaec3af6",
    "_kg_hide-input": false,
    "_uuid": "ba055913c5b6e401556f7e63647ecd6f51759f66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# models\n",
    "from sklearn import feature_selection\n",
    "#import xgboost as xgb\n",
    "#import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn import preprocessing\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import scipy.stats as st\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.plotly as py\n",
    "import gc\n",
    "\n",
    "# Load\n",
    "train = pd.read_csv(\"train.csv\",index_col=\"id\",low_memory=False,\n",
    "                    parse_dates=[\"project_submitted_datetime\"])#.sample(1000,random_state=23)\n",
    "traindex = train.index\n",
    "test = pd.read_csv(\"test.csv\",index_col=\"id\",low_memory=False,\n",
    "                    parse_dates=[\"project_submitted_datetime\"])#.sample(1000,random_state=23)\n",
    "tesdex = test.index\n",
    "y = train[\"project_is_approved\"].copy()\n",
    "df = pd.concat([train.drop(\"project_is_approved\",axis=1),test],axis=0)\n",
    "alldex = df.index\n",
    "\n",
    "# Resource DF\n",
    "rc = pd.read_csv(\"resources.csv\",index_col=\"id\").fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9e61c6e4-4d24-4d34-a7ca-b3e3c67211cc",
    "_uuid": "088fa92ff86e60d75ed5ce606d107750543fd2c4"
   },
   "source": [
    "*Imbalanced Depedent Variable - Brief Visualizations*\n",
    "\n",
    "- This is always a key aspect to review when conducting Machine Learning.\n",
    "- My model must take this into account, or else it will struggle to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "435706ad-ad30-455a-a22b-0f483ed09b45",
    "_kg_hide-input": true,
    "_uuid": "9c2d0ec20eecc787c347417f06c97f6332da0248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approved: 84.7682337434095%\n",
      "Denied: 15.23176625659051%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVwAAAEfCAYAAAAN2n7uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2cbb3ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Percentages\n",
    "print(\"Approved: {}%\\nDenied: {}%\".format(*y.value_counts(normalize=True)*100))\n",
    "\n",
    "# Plot\n",
    "f, ax = plt.subplots(figsize=[5,4])\n",
    "sns.countplot(y,ax=ax, palette=\"rainbow\")\n",
    "ax.set_title(\"Dependent Variable Imbalance\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xlabel(\"Project Approval Status\\n0: Denied, 1: Approved\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ae5a439d-6589-423f-94f5-11a8a7fecf08",
    "_uuid": "5f4b3a79a63a654a0683fa6977aec9380c713cc4"
   },
   "source": [
    "*Here, the resource dataset is delt with:*\n",
    "\n",
    "- Here the `groupby` function uses the `.agg` extension to compute multiple different descriptive statistics for multiple different columns.\n",
    "- Since this function outputs columns with multiple-index, I combine elements from both tiers and collapse them.\n",
    "- Since some teachers only posted one requested resource entry in the resource df, those teachers have their *price_std* as NA. Delt with this problem with `.fillna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "a0111d9e-4f08-4a31-af20-96eb8262a0bf",
    "_uuid": "79cd2a756e3f76f69e2f366f4a6cd3c7a3ac1941"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "869"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate and Merge\n",
    "agg_rc = rc.reset_index().groupby('id').agg(\n",
    "    dict(quantity = ['sum',\"mean\"],\n",
    "         price = [\"sum\",\"mean\",\"max\",\"min\",\"std\"],\n",
    "         id = 'count',\n",
    "         description = lambda x: ' nicapotato '.join(x))).rename(columns={\"id\" : \"count\"})\n",
    "\n",
    "# Collapse Multi-index\n",
    "agg_rc.columns = pd.Index([e[0] +\"_\"+ e[1] for e in agg_rc.columns.tolist()])\n",
    "agg_rc.rename({'count_count':\"count\",'description_<lambda>': \"description\"},inplace=True)\n",
    "agg_rc.price_std.fillna(0,inplace=True)\n",
    "\n",
    "# Merge\n",
    "df = pd.merge(df,agg_rc, left_index=True, right_index=True, how= \"left\")\n",
    "del test, train, rc,agg_rc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0c241f57-2121-4328-8acf-868869f9a060",
    "_uuid": "86d1972bca2c7646d4167e956b6639a81a69a1d6"
   },
   "source": [
    "*Project Essays are joined together with a space in between*\n",
    "\n",
    "- This step is in preperation of Term Frequency-Inverse Document Frequency **[TF-IDF]**\n",
    "- Thanks to [Heads or Tails'](https://www.kaggle.com/c/donorschoose-application-screening/discussion/51352) sleuthing, I know that DonorChoose.org reduced the number of essays in its applications from four to two after May 17 2016. By combining all four, this alleviates some of the problem, but applications pre-cutoff may be skewed since they will have more words.\n",
    "- Lastly, its best practise to review the distributions and trends in the data before attempting to build a model. Heads or Tails has a [comprehensive notebook](https://www.kaggle.com/headsortails/an-educated-guess-donorschoose-eda) available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "df['text'] = df.apply(lambda row: ' '.join([\n",
    "    str(row['project_essay_1']), \n",
    "    str(row['project_essay_2']), \n",
    "    str(row['project_essay_3']), \n",
    "    str(row['project_essay_4'])]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "efedb962-70c7-4836-a76d-43090396c1d1",
    "_uuid": "475fe7b31c6482137dfa710af9ccf65338fb4c96"
   },
   "source": [
    "*Numerous hand made features with Sentiment Analysis:* <br>\n",
    "- Compound, Neutral, Negative and Positive Sentiment is collected.\n",
    "- **Neutral/Negative/Positive Score:** Indicates the potency of these classes between 0 and 1.\n",
    "- **Polarity Score:** Measures the difference between the Positive/Neutral/Negative values, where a positive numbers closer to 1 indicates overwhelming positivity, and a negative number closer to -1 indicates overwhelming negativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "1ff5d863-a9ac-4bcf-945d-a83337aae255",
    "_uuid": "f6f8af02bd7b68054484ee524c2625220d1c0dd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hand Made Text Features..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f966998a4a13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n# Text Features for feature extraction\\ntext_cols = [\"text\",\"project_resource_summary\", \"project_title\", \"description\"]\\n\\n# Sentiment Build\\nprint(\"Hand Made Text Features..\")\\nSIA = SentimentIntensityAnalyzer()\\nfor cols in text_cols:\\n    df[cols] = df[cols].astype(str) # Make Sure data is treated as string\\n    df[cols] = df[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\\n    df[cols+\\'_num_chars\\'] = df[cols].apply(len) # Count number of Characters\\n    df[cols+\\'_num_words\\'] = df[cols].apply(lambda comment: len(comment.split())) # Count number of Words\\n    df[cols+\\'_num_unique_words\\'] = df[cols].apply(lambda comment: len(set(w for w in comment.split())))\\n    # Count Unique Words\\n    df[cols+\\'_words_vs_unique\\'] = df[cols+\\'_num_unique_words\\'] / df[cols+\\'_num_words\\']*100\\n    # Unique words to Word count Ratio\\n    if cols == \"text\":\\n        df[cols+\"_vader_Compound\"]= df[cols].apply(lambda x:SIA.polarity_scores(x)[\\'compound\\'])\\n    #     df[cols+\\'_vader_Neutral\\']= df[cols].apply(lambda x:SIA.polarity_scores(x)[\\'neu\\'])\\n    #     df[cols+\\'_vader_Negative\\']= df[cols].apply(lambda x:SIA.polarity_scores(x)[\\'neg\\'])\\n        df[cols+\\'_vader_Positive\\']= df[cols].apply(lambda x:SIA.polarity_scores(x)[\\'pos\\'])\\n        # Test a Stemmer..\\n    print(\"{} Done\".format(cols))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2353\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer (pandas/_libs/lib.c:66440)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36mpolarity_scores\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mvalence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \"\"\"\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0msentitext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentiText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;31m#text, words_and_emoticons, is_cap_diff = self.preprocess(text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords_and_emoticons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_words_and_emoticons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;31m# doesn't separate words from\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# adjacent punctuation (keeps emoticons & contractions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m_words_and_emoticons\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \"\"\"\n\u001b[1;32m    191\u001b[0m         \u001b[0mwes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mwords_punc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_words_plus_punc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mwes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m_words_plus_punc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mwords_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords_only\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# the product gives ('cat', ',') and (',', 'cat')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mpunc_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPUNC_LIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mpunc_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPUNC_LIST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mwords_punc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpunc_before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mwords_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords_only\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# the product gives ('cat', ',') and (',', 'cat')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mpunc_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPUNC_LIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mpunc_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPUNC_LIST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mwords_punc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpunc_before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Text Features for feature extraction\n",
    "text_cols = [\"text\",\"project_resource_summary\", \"project_title\", \"description\"]\n",
    "\n",
    "# Sentiment Build\n",
    "print(\"Hand Made Text Features..\")\n",
    "SIA = SentimentIntensityAnalyzer()\n",
    "for cols in text_cols:\n",
    "    df[cols] = df[cols].astype(str) # Make Sure data is treated as string\n",
    "    df[cols] = df[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
    "    df[cols+'_num_chars'] = df[cols].apply(len) # Count number of Characters\n",
    "    df[cols+'_num_words'] = df[cols].apply(lambda comment: len(comment.split())) # Count number of Words\n",
    "    df[cols+'_num_unique_words'] = df[cols].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    # Count Unique Words\n",
    "    df[cols+'_words_vs_unique'] = df[cols+'_num_unique_words'] / df[cols+'_num_words']*100\n",
    "    # Unique words to Word count Ratio\n",
    "    if cols == \"text\":\n",
    "        df[cols+\"_vader_Compound\"]= df[cols].apply(lambda x:SIA.polarity_scores(x)['compound'])\n",
    "    #     df[cols+'_vader_Neutral']= df[cols].apply(lambda x:SIA.polarity_scores(x)['neu'])\n",
    "    #     df[cols+'_vader_Negative']= df[cols].apply(lambda x:SIA.polarity_scores(x)['neg'])\n",
    "        df[cols+'_vader_Positive']= df[cols].apply(lambda x:SIA.polarity_scores(x)['pos'])\n",
    "        # Test a Stemmer..\n",
    "    print(\"{} Done\".format(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1452258b-a31a-454c-9c4e-ffb8d5267c61",
    "_uuid": "f95b85afbf21fc53f4d204b52f2424d318b9bff2"
   },
   "source": [
    "*Number of Words before and after May 17, 2016*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "6e078f85-87b4-40df-973b-f1b4218fab58",
    "_uuid": "bf25cd83b5716c02ff8ce818d7671fb9ef3915f1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Date Cutoff Variable\n",
    "df[\"Date_Cutoff\"] = None\n",
    "df.loc[df[\"project_submitted_datetime\"] > \"05/16/2016\",\"Date_Cutoff\"] = \"After\"\n",
    "df.loc[df[\"project_submitted_datetime\"] <= \"05/16/2016\",\"Date_Cutoff\"] = \"Before\"\n",
    "\n",
    "# Plot\n",
    "f, ax = plt.subplots(1,4, figsize=[14,4])\n",
    "for i, plotcol in enumerate([\"text_num_words\",\"text_num_unique_words\",\"text_words_vs_unique\",\"text_vader_Compound\"]):\n",
    "    sns.boxplot(data=df, y=plotcol,x=\"Date_Cutoff\",ax=ax[i], palette=\"rainbow\")\n",
    "    ax[i].set_xlabel(\"May 17th 2016 Cutoff\")\n",
    "    ax[i].set_ylabel(\"{}\".format(plotcol.replace(r'_',' ').capitalize()))\n",
    "    ax[i].set_title(\"{}\\nby Date Cutoff\".format(plotcol.replace(r'_',' ').capitalize()))\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "775cfbd7-ec99-4d3d-98df-8d3182ea30a2",
    "_uuid": "02701945aad234e98bb8189cc656827e20f7f161"
   },
   "source": [
    "There is a difference between groups.\n",
    "***\n",
    "*Time and Categories Features*\n",
    "- For time, I choose to isolate:\n",
    "    - Year,\n",
    "    - Day of the Year\n",
    "    - Weekday\n",
    "    - Day of the Month\n",
    "    - Quarter of the Year\n",
    "- *Project Subject Categories and Subcategories* are tricky since various schooling departments, such as: Math, Literature, etc.. are combined and seperated by a comma. To tackle this, the string parser `sep=', '` is used within the `get_dummies` arguements, swiftly seperating and encoding the various subjects.\n",
    "- Next I handle *Teacher_id*. Originally, I had encoded this with `LabelEncoder`, but after further examination, I noticed that most teachers sent one app total, with a minority of 58 submitting two. Encoding and even dummy variables don't capture this pattern because it is unable to generalize is into \"teachers who have sent more than one application\". Thats why I created a boolean variable to capture that - *'multi_apps'*.\n",
    "- After, I create an clearer *Gender* variable, but decide to keep the original teacher prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "d1a8bf36-5d7d-416a-b926-0be6026de481",
    "_uuid": "869aae3e8e241167b59450e24ca3fd3d2e6712aa",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Time Variables\n",
    "df[\"Year\"] = df[\"project_submitted_datetime\"].dt.year\n",
    "df[\"Date of Year\"] = df['project_submitted_datetime'].dt.dayofyear # Day of Year\n",
    "df[\"Weekday\"] = df['project_submitted_datetime'].dt.weekday\n",
    "df[\"Weekd of Year\"] = df['project_submitted_datetime'].dt.week\n",
    "df[\"Day of Month\"] = df['project_submitted_datetime'].dt.day\n",
    "df[\"Quarter\"] = df['project_submitted_datetime'].dt.quarter\n",
    "\n",
    "# Split the strings at the comma, and treat them as dummies\n",
    "df = pd.merge(df, df[\"project_subject_categories\"].str.get_dummies(sep=', '),\n",
    "              left_index=True, right_index=True, how=\"left\")\n",
    "df = pd.merge(df, df[\"project_subject_subcategories\"].str.get_dummies(sep=', '),\n",
    "              left_index=True, right_index=True, how=\"left\")\n",
    "              \n",
    "# Teacher ID\n",
    "teachr_multi_subs = df['teacher_id'].value_counts().reset_index()\n",
    "df[\"multi_apps\"]= df['teacher_id'].isin(teachr_multi_subs.loc[teachr_multi_subs[\"teacher_id\"]>1,'index'].tolist())\n",
    "# Percentages\n",
    "print(\"Teacher App Distribution:\\nTwo Apps: {}%\\nOne App: {}%\\n\".format(*df[\"multi_apps\"].value_counts(normalize=True)*100))\n",
    "\n",
    "# Teacher Gender\n",
    "df[\"Gender\"] = None\n",
    "df.loc[df['teacher_prefix'] == \"Mr.\",\"Gender\"] = \"Male\"\n",
    "df.loc[df['teacher_prefix'] == \"Teacher\",\"Gender\"] = \"Not Specified\"\n",
    "df.loc[(df['teacher_prefix'] == \"Mrs.\")|(df['teacher_prefix'] == \"Ms.\"),\"Gender\"] = \"Female\"\n",
    "\n",
    "print(\"Gender Distribution:\\nFemale: {}%\\nMale: {}%\\nNot Specified: {}%\".format(*df[\"Gender\"].value_counts(normalize=True)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fff56295-de96-4465-9957-3ab427cf927c",
    "_uuid": "24c64277575de1b8d0d96401a50229400d3c37e0"
   },
   "source": [
    "Women professors are overwhelmingly more likely to request funding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "f1bf8bca-94b6-4d69-a5b0-2efd2c36fb83",
    "_uuid": "054bcb049aff292214c5d3e37ba92d6148415966",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Heatmap to see Gender and Teaching Grade of Teachers\n",
    "f, ax = plt.subplots(figsize=[6,4])\n",
    "sns.heatmap(pd.crosstab(df.project_grade_category,df.Gender,normalize='columns').mul(100).round(0),\n",
    "            annot=True, linewidths=.5,fmt='g', cmap=\"rainbow\", vmin=0, vmax=100,ax=ax,\n",
    "            cbar_kws={'label': '% Percentage'})\n",
    "ax.set_title(\"Percentage by Row of Gender in Grade Range\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "33f33286-3830-4dc2-a8df-55c1a51e0760",
    "_uuid": "aee3f8e2a29e1d18a496b41470cb80df4279a345"
   },
   "source": [
    "According to the [Association of American Educators](https://www.aaeteachers.org/index.php/blog/757-the-teacher-gender-gap) quote:\n",
    "> \"Male educators constitute just 2.3% of pre-K and kindergarten teachers, 18.3% of the elementary and middle school teacher population, and 42% of the high school level teaching staff.  These numbers are down from 2007, but suggest a clear female majority in the teaching profession, especially in the earlier grades. (source: [BLS](https://www.bls.gov/cps/cpsaat11.pdf))\"\n",
    "\n",
    "***\n",
    "*`Dummy` and `LabelEncoding`:*\n",
    "- Since *Project Grade Category* is ordinal in nature, as in the escalation from elementary to primary school signifies older students, it receives `LabelEncoder`. *Multi-apps* and *Date cutoff* are also of interest, so they were be transformed from True/False to Boolean (1,0).\n",
    "- Lastly, I dummy encoded the time variables, aswell as *teacher_prefix*, *school_state*, *project_grade_category*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "0c5c2555-4c99-412b-8226-dc778235ef60",
    "_uuid": "58098f4cced5146ea6132168ac904e148698037b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoder:\n",
    "encode = [\"project_grade_category\",'multi_apps', \"Date_Cutoff\", 'teacher_prefix',\"teacher_id\"]\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for col in encode:\n",
    "     df[col] = lbl.fit_transform(df[col].astype(str))\n",
    "\n",
    "# Dummies:\n",
    "timevars = ['Weekday','Weekd of Year','Day of Month','Year','Date of Year',\"Quarter\"]\n",
    "df = pd.get_dummies(df, columns=[\"Gender\",'school_state','project_grade_category']+timevars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "ac847d8b-5d81-4a93-afcf-923535290ce8",
    "_uuid": "bc07198fda1a03212ba5199b976608e6a1213deb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Text\n",
    "text_cols = [\"project_resource_summary\", \"project_title\",\"description\",\"text\"]\n",
    "\n",
    "df.drop(['project_subject_categories',\"project_subject_subcategories\",\"project_submitted_datetime\",\n",
    "         \"project_essay_1\",\"project_essay_2\",\"project_essay_3\",\"project_essay_4\"\n",
    "        ],axis=1,inplace=True)\n",
    "normalize = [\"teacher_number_of_previously_posted_projects\",\"quantity\",\"price\"]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "345c8348-8f22-43ab-8df5-2406c1d11356",
    "_uuid": "a672e1e75bd94311778826bab5b254f4cc71c824"
   },
   "source": [
    "***\n",
    "## **[TF-IDF]** : *Term Frequency-Inverse Document Frequency*  <br>\n",
    "\n",
    "This is a text processing stage in the *Bag of Words* family. \n",
    "- Text processing means turning chunks of text into something machine learning models can understand.. So some kind of numeric representation.\n",
    "- Bag of Words signifies that it looks for word occurence in text chunk, and completely ignores the sequencial significance of language (to the extent that n-grams are used..)\n",
    "\n",
    "**TF-IDF** calculates how important a word is in a document (in this case, a text feature such as *all the paragraphs*) in comparison to the entire corpus (so all the paragraphs by *ALL* the teachers)\n",
    "\n",
    "Resources: <br>\n",
    "- [Scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "- [Bill Chamber's Blog Post](http://billchambers.me/tutorials/2014/12/21/tf-idf-explained-in-python.html)\n",
    "\n",
    "My Parameters: <br>\n",
    "- **sublinear:** Regularization technique, that squishes the data to a lower, common magnitude -> 1 + log(tf)\n",
    "- **strip_accents:** Gets rid of any special characters from foreign languages. These essays are all in English so that shoudn't make a difference.\n",
    "- **stop_words:** This cleans the text for common, low-impact, filler words such as the, a, an, in ..etc, to make way for words that distinguish.\n",
    "- **analyzer:** Choice between *Word* and *Character*. Textual level of analysis. In our case, *Word* is ideal since its all the text is in English with formal and clean spelling. This is not always the case. For example for the [Toxic Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge), characters are also saught after. Heck, try it on this set of data, but beware the risk of overfitting.\n",
    "- **token_pattern:** Regular Expression to define specification of words saught. Let's further explain`r'\\w{1,}'`\n",
    "    - `r\"\"`: This  treats the piece as raw code, so that backslashes are treated as part of the regex, instead of attempting to format the string (Like \\n would go to the line)\n",
    "    - `\\w`: Specifies only letters, numbers and _ spaces. Sorry aliens :(\n",
    "- **ngram_range:** Specify the size of each word \"token\". If the range is (2,3), then two and three consecutive word groups will be selected to vectorize.\n",
    "- **max_features:** Maximum number of features created. If `none`, then only top features are considered. Tune this threshold with *min_df and max_df*.\n",
    "- **norm:** Its easy to assume that this is a form of normalization in the likes of Ridge or Lasso. However, that is incorrect.\n",
    "    - `l2` infact refers to *Cosine Distance*, which normalizes our vectorizer to documents of variant length. Therefore, the fact that teachers only submitted two essasys after May 17th 2016 is delt with. \n",
    "    - [Now in our case, if the cosine similarity is 1, they are the same document. If it is 0, the documents share nothing.](http://billchambers.me/tutorials/2014/12/22/cosine-similarity-explained-in-python.html)\n",
    "    - I am keeping the May 17th 2016 cutoff variable just incase to cross-reference the decision tree feature importance.\n",
    "\n",
    "**min_df and max_df:** [Quoted Verbatum from Kevin Markham's StackOverflow post](https://stackoverflow.com/questions/27697766/understanding-min-df-and-max-df-in-scikit-countvectorizer)<br>\n",
    "max_df is used for removing terms that appear too frequently, also known as \"corpus-specific stop words\". For example:\n",
    "- **max_df** = 0.50 means \"ignore terms that appear in more than 50% of the documents\".\n",
    "- **max_d**f = 25 means \"ignore terms that appear in more than 25 documents\".\n",
    "The default max_df is 1.0, which means \"ignore terms that appear in more than 100% of the documents\". Thus, the default setting does not ignore any terms.\n",
    "\n",
    "min_df is used for removing terms that appear too infrequently. For example:\n",
    "- **min_df** = 0.01 means \"ignore terms that appear in less than 1% of the documents\".\n",
    "- **min_d*f** = 5 means \"ignore terms that appear in less than 5 documents\".\n",
    "The default min_df is 1, which means \"ignore terms that appear in less than 1 document\". Thus, the default setting does not ignore any terms.\n",
    "\n",
    "-**Smooth_Idf:** Whether to add a zero to the numerator and denominator of the TD-IDF. Prevents zero division, where some words in the training process get ignored.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6c5fb109-9ab0-4ca3-a6f5-108b26c62189",
    "_uuid": "6490b5e1800a12dd990d41754cd8ac2b7cdaeeba"
   },
   "source": [
    "\n",
    "*Here, TD-IDF is applied to: **Text, Project Resource Summary, Project Title and Description** Seperately*\n",
    "- I decided to take this approach in order to not miss out on the specific purpose that these text chunks serve. For example, project_resource_summary tends to include the exact items seeking funding. Perhaps `Coutvectorizin` this could give the model more information about the types of items that receive the most funding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "164c0114-d1f7-4626-85db-4fdf9d167d48",
    "_uuid": "3458ee65eb341df9606a1f4c38e5de2886308695",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets look at these variables!\n",
    "print(\"\\nDtypes of DF features:\\n\",df.dtypes.value_counts())\n",
    "print(\"\\nDF Shape: {} Rows, {} Columns\".format(*df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "0e06c8b2-e506-4eaa-8018-4fbe2c45fdd1",
    "_uuid": "42b0d437a514eee52ad4c80da7e3a8e2d79fdf4b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_para = {\n",
    "    \"sublinear_tf\":True,\n",
    "    \"strip_accents\":'unicode',\n",
    "    \"stop_words\":\"english\",\n",
    "    \"analyzer\":'word',\n",
    "    \"token_pattern\":r'\\w{1,}',\n",
    "    #\"ngram_range\":(1,1),\n",
    "    \"dtype\":np.float32,\n",
    "    \"norm\":'l2',\n",
    "    \"min_df\":5,\n",
    "    \"max_df\":.8,\n",
    "    \"smooth_idf\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3905713a-3c24-4a41-8841-20fa915d368d",
    "_uuid": "2286f218c781f54b80c73764add5ec245231e22e"
   },
   "source": [
    "*Reflection on my parameters:* <br>\n",
    "Something I noticed about my model is its tendency to overfit massively, boasting a training AUC score in the ~0.9s, while maintaining a validation score in the high ~0.7s. To tackle this, I am trying to be harsher on my word vectors, increasing the minimum required occurence of words, as well as getting rid of more common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "ce44a0cf-d9e7-4b70-98c9-b343238a779f",
    "_uuid": "62026d86afb5eeb9c78ac6aeb1d01f7d50878527",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Thanks To\n",
    "# https://www.kaggle.com/lopuhin/eli5-for-mercari\n",
    "# https://www.kaggle.com/jagangupta/understanding-approval-donorschoose-eda-fe-eli5/notebook\n",
    "\n",
    "def get_col(col_name):\n",
    "    return lambda x: x[col_name]\n",
    "\n",
    "textcols = [\"text\",\"project_resource_summary\",\"project_title\",\"description\"]\n",
    "vectorizer = FeatureUnion([\n",
    "        ('text',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=20000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col('text'))),\n",
    "        ('project_resource_summary',TfidfVectorizer(\n",
    "            ngram_range=(1, 1),\n",
    "            **tfidf_para,\n",
    "            max_features=2000,\n",
    "            preprocessor=get_col('project_resource_summary'))),\n",
    "        ('project_title',TfidfVectorizer(\n",
    "            ngram_range=(1, 1),\n",
    "            **tfidf_para,\n",
    "            max_features=1500,\n",
    "            preprocessor=get_col('project_title'))),\n",
    "        ('description',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            **tfidf_para,\n",
    "            max_features=2000,\n",
    "            preprocessor=get_col('description'))),\n",
    "#         ('Non_text',DictVectorizer())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "2a9baeac-1fca-4988-9a13-3f14b58f2d9c",
    "_uuid": "225504597b006b57be548c5d729f910f4bebd5c3",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_vect=time.time()\n",
    "ready_df = vectorizer.fit_transform(df.to_dict('records'))\n",
    "tfvocab = vectorizer.get_feature_names()\n",
    "print(\"Vectorization Runtime: %0.2f Minutes\"%((time.time() - start_vect)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a457eca4-8c06-47b9-a173-4ab5ae188860",
    "_uuid": "075be7ddf4a0d4f787d146594462d8215aea9beb"
   },
   "source": [
    "*Lets look at the top features in the Training Set!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "28197013-5c87-4f30-9fdc-d77deba1dc8d",
    "_uuid": "b5cc23b4342ee497b14cec62b48a5863727f451e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort and Print\n",
    "feature_array = np.array(vectorizer.get_feature_names())\n",
    "tfidf_sorting = np.argsort(ready_df.toarray()).flatten()[::-1]\n",
    "print(\"Most Important Words in All Vectorization:\\n\",feature_array[tfidf_sorting][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7f2d98e3-083b-4886-8192-0660d43533fb",
    "_uuid": "d16c574d5635d38aa2f5d34f869f70972b97102d"
   },
   "source": [
    "These steps are important because it enables a peak into the model's psychology. That is: what is it picking up on, and is that what we had in mind? Does it seem unconnected to receiving grants? Is it *ethical*?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "c063a9e3-93c5-45df-be96-2bea3460b691",
    "_uuid": "d56dede443f875125afb6058b7826c475ff8f8b9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(textcols,axis=1, inplace=True)\n",
    "# Lets look at these variables!\n",
    "print(\"\\nDtypes of DF features:\\n\",df.dtypes.value_counts())\n",
    "print(\"\\nDF Shape: {} Rows, {} Columns\".format(*df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5daef562-52c3-40a0-8c6a-3cf1d0d6da9a",
    "_uuid": "9ec605d3798e5d351bef8f5dbf1421791c5d4701"
   },
   "source": [
    "\n",
    "***\n",
    "## Modeling with eXtreme Gradient Boosting\n",
    "\n",
    "**Make Dense dataframe Sparse, and Combine with TF-IDF features:** <br>\n",
    "This step is to consolidate all the features created into one cohesive training and test set.\n",
    "\n",
    "You have have noticed `gc.collect()` sprinkled here and there. It stands for *\"Garbage Collector\"*, and it releases unreferenced memory. So it is utilized when large/ data is deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "22583e8b-62a7-48c3-a385-6f6ce0d797db",
    "_uuid": "d25ce57b6cb5d449a5a0d6c96b2d5dd2c7ab167a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = hstack([ready_df[0:traindex.shape[0]],csr_matrix(df.loc[traindex,:].values)])\n",
    "testing = hstack([ready_df[traindex.shape[0]:],csr_matrix(df.loc[tesdex,:].values)])\n",
    "tfvocab = tfvocab + df.columns.tolist()\n",
    "for shape in [X,testing]:\n",
    "    print(\"{} Rows and {} Cols\".format(*shape.shape))\n",
    "print(\"Feature Names Length: \",len(tfvocab))\n",
    "del df\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5bca9dac-4301-41ec-a021-a9a7da98c2cf",
    "_uuid": "16902f6b436db37aaa240adddeff59e089d6cc47"
   },
   "source": [
    "*Train and Validation:* <br>\n",
    "- Validation is extremely important to ensure the models generalizability for cases outside the training set! \n",
    "- `DMatrix` from the xgboost package is an extremely important step, enabling the model to handle much more data at a higher dimensionality more efficiently! [Big Shoutou to jmbull and his kernel](https://www.kaggle.com/jmbull/xtra-credit-xgb-w-tfidf-feature-stacking/notebook) which helped me out tremendously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "51424970-b8fe-4090-9702-446ffa5fec0a",
    "_uuid": "fac1bb40c778ce9bba3ee18710a196482a8717f2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training and Validation Set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=23)\n",
    "\n",
    "# XGBOOST Sparse Feature Storage\n",
    "d_train = xgb.DMatrix(X_train, y_train,feature_names=tfvocab)\n",
    "d_valid = xgb.DMatrix(X_valid, y_valid,feature_names=tfvocab)\n",
    "d_test = xgb.DMatrix(testing,feature_names=tfvocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5886099e-b034-44cd-a417-4b5cea50d9de",
    "_uuid": "37ccde9aa16e8fcb85ab1b2bd31467ef5863cc12"
   },
   "source": [
    "***\n",
    "This part is heavily influenced from my **[Introduction to Classification with Titanic](https://www.kaggle.com/nicapotato/titanic-voting-pipeline-stack-and-guide)**, which takes a conceptual look at over 10 models, and explains how they fit within different paradigms. Check it out!\n",
    "***\n",
    "## Model Paradigm:\n",
    "**Decision Trees:** <br>\n",
    "I like to think of decision trees as optimizing a series of “If/Then” statements, eventually assigning the value at the tree’s terminal node. Starting from one point at the top, features can then pass the various trials until being assigned its class at the end “leaf” nodes of the tree (technically, it's more like its root tip since the end nodes are visually represented at the bottom of the graph). Trees used here are binary trees, so nodes can only split into two ways.\n",
    "\n",
    "**Gradient Boosting:** <br>\n",
    "As the name suggest, Gradient Boosting iteratively trains models sequentially to minimize its objective function. This is a Greedy Algorithm, which makes the most favorable split when it can. This means it's short sighted and will also stop when the loss doesn’t improve.\n",
    "\n",
    "**XGBoost - eXtreme Gradient Boosting: ** <br>\n",
    "As the name suggest, Gradient Boosting on steroids. Infact, multiple steroids:\n",
    "- **Regularization**\n",
    "- **Computation Speed** and **Parallel Processing**\n",
    "- Handles **Missing Values**\n",
    "- Improves on Gradient Boosting ***'Greedy'*** tendencies. It does this by considering reaching the max depth and retroactively pruning \n",
    "- **Interruptible** and **Resumable**, as well as **Hadoop** capabilities.\n",
    "\n",
    "XGBoost is able to approximate the Loss function more efficiently, thereby leading to faster computation and parallel processing. Inside its objective function, it has also incorporated a regularization term, L1 and L2, to stay clear of unnecessary high dimensional spaces and complexity.\n",
    "\n",
    "## Hyper-Parameters:\n",
    "*Some of these parameter names are for the scikit learn xgboost wrapper* <br>\n",
    "\n",
    "**General Decision Tree Hyper-Parameters:** <br>\n",
    "- **max_features:** This is the random subset of features to be considered for splitting operation, the lower the better to reduce variance. For Classification model, ideal max_features = sqr(n_var).\n",
    "- **max_depth:** Maximum depth of the tree. Alternate method of control model depth is max_leaf_nodes, which limits the number of terminal nodes, effectively limiting the depth of the tree.\n",
    "- **n_estimators:** Number of trees built before average prediction is made.\n",
    "- **min_samples_split:** Minimum number of samples required for a node to be split. Small minimum would potentially lead to a “Bushy Tree”, prone to overfitting. According to Analytic Vidhya, should be around 0.5~1% of the datasize.\n",
    "- **min_samples_leaf:** Minimum number of samples required at the Terminal Node of the tree. In Sklearn, an alternative min_weight_fraction_leaf is available to use fraction of the data instead of a fixed integer.\n",
    "- **random_state:** Ensuring consistent random generation, like seed(). Important to consider for comparing models of the same type to ensure a fair comparison. May cause overfitting if random generation is not representative.\n",
    "\n",
    "**Gradient Boosting Specific Hyper-Parameters:** <br>\n",
    "- **eta: ** How much parameters are updated after each iteration of gradient descent. Low mean smaller steps, most likely to reach the global minimum, although there are cases where this doesn’t always work as intended.\n",
    "- **n_estimators:** Note this is still the number of trees being built, but it within the GBC’s sequential methodology.\n",
    "- **subsample:** Similar to the Bootstrap Aggregate method, controlling percentage of data utilized for a tree, although the standard is to sample *without* replacement. In this model, operates in similar ways to Stochastic Gradient Descent in Neural Networks, but with large batch sizes. <br>\n",
    "*Note this decision trees are still a *Shallow Model*, so it is still profoundly different from Neural Networks.*\n",
    "- **loss:** Objective Function minimized by gradient descent.\n",
    "- **init:** Initialization of the model internal parameters. May be used to build off another model's’ outcome.\n",
    "\n",
    "**Hyper-Parameters for Tree Classification Booster (Sklearn Wrapper):** <br>\n",
    "- **Min_child_weight:** Similar strand to *min_child_leaf*, which controls the minimum number of observation to split to a terminal node. This instead relates to defines the minimum sum of derivatives found in the Hessian (second-order)of all observations required in a child.\n",
    "- **Gamma:** Node is split only if it gives a positive decrease in the loss function. Higher performance regulator of complexity.\n",
    "- **Max_delta_step:** What the tree’s weights can be.\n",
    "- **Colsample_bylevel:** Random Forest characteristic, where it enables subfraction of features to be randomly selected for each tree.\n",
    "\n",
    "**Regularization:** <br>\n",
    "In the context of GBMs, regularization through shrinkage is available, but applying it to the model with the tree base-learner is different from its traditional coefficient constriction. For GBM Trees, the shrinking decreases the influence of each additional tree in the iterative process, effectively applying a decay of impact over boosting rounds. As a result, it no longer searches as the feature selection method, since it cannot adjust the coefficients of each feature (and potential interaction/ polynomial terms).\n",
    "\n",
    "**Learning Task Parameters:**\n",
    "- **Objective:** *binary:logistic* = Outputs probability for two classes.\n",
    "- **Multi:** *softmax* = outputs prediction for *num_class* classes.\n",
    "- **Multi:** *prob* = probability for 3 or more classes.\n",
    "\n",
    "The objective is merely a matter of catering to the data type, although additional protocols on the probabilities may be set up. For example, the highest probability below a certain threshold may be deemed an inadequate score, passed over for human processing. The optimal loss function should cater to the behavior of the data and goal at hand, and usually requires input from the domain knowledge base.\n",
    "\n",
    "The Evaluation Metric (*eval_metric*) has important implications depending on the problem at hand. If the dataset is imbalanced and the minority class is of interest, it is better to use [AUC] Area Under the Curve than accuracy or rmse, since those metrics can get away with assigning the majority class to all, and still get away with high accuracy!\n",
    "\n",
    "*More Info:* <br>\n",
    "- [Complete Guide to Parameter Tuning in Gradient Boosting (GBM) in Python by Analytics Vidhya](https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/) \n",
    "- [Gradient boosting machines, a tutorial by Alexey Natekin1 and Alois Knoll](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3885826/)\n",
    "- [Complete Guide to XGBOOST with Analytic Vidhya](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)\n",
    "- [Python Installation Instructions](https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_XGBoost_For_Anaconda_on_Windows?lang=en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "e0693a65-8a6b-4f4c-976b-76daa72db6f5",
    "_uuid": "f35a6750867b89e3620f6b22bd0f34ae9fdfe7fc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {'eta': 0.1, \n",
    "              'max_depth': 8, \n",
    "              'subsample': 0.8, \n",
    "              'colsample_bytree': 0.8,\n",
    "              'min_child_weight' : 1.5,\n",
    "              'scale_pos_weight': (y.value_counts()[0]/y.value_counts()[1]),\n",
    "              'objective': 'binary:logistic', \n",
    "              'eval_metric': 'auc', \n",
    "              'seed': 23,\n",
    "              'lambda': 1.5,\n",
    "              'alpha': .6\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "3ebaef30-e26f-4b12-8bd2-7297c9821e96",
    "_uuid": "ec7256297133ebbe9d4f5b26452a335a1d238142",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelstart = time.time()\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "model = xgb.train(xgb_params, d_train, 500, watchlist, verbose_eval=50, early_stopping_rounds=50)\n",
    "xgb_pred = model.predict(d_test)\n",
    "\n",
    "xgb_sub = pd.DataFrame(xgb_pred,columns=[\"project_is_approved\"],index=tesdex)\n",
    "xgb_sub.to_csv(\"xgb_sub.csv\",index=True)\n",
    "print(\"Model Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f07e0c9d-a4ae-439c-8330-75415fe86165",
    "_uuid": "738662598a88fd72f3c0bde380ca9ee20bb0c96f"
   },
   "source": [
    "*Reflection on Parameters:* <br>\n",
    "Coming up once optimal parameters found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dafdbe5f-fc90-42df-b847-bb0c5bbf4bd8",
    "_uuid": "18c6c54ac566fa434c1d28790f78bbc1cbabc26c"
   },
   "source": [
    "*Model Interpretation:* <br>\n",
    "Disclaimer: <br>\n",
    "I stiched together the feature names from the various pre-processing steps, and I am concerned that this may not have translated correctly. I hope see if this checks out with other decision trees.\n",
    "\n",
    "*Introducing the Feature Importance Bar Plot:* <br>\n",
    "Since each split in the decision tree distinguishes the dependent variable, splits closer to the root, aka starting point, have optimally been determined to have the greatest splitting effect. The feature importance graphic measures how much splitting impact each feature has. It is important to note that this by no means points to causality, but just like in hierarchical clustering, does point to a nebulous groups. Furthermore, for ensemble tree methods, feature impact is aggregated over all the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_cell_guid": "3e772db1-54b9-4a11-b171-5d8b508c9126",
    "_kg_hide-input": false,
    "_uuid": "66ba7b3b31f9fd3dc297f1711d6a0e515010531c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=[7,10])\n",
    "xgb.plot_importance(model,max_num_features=50,ax=ax)\n",
    "plt.title(\"XGBOOST Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "61640f95-80eb-46cf-b405-83d86372c22d",
    "_uuid": "c46d81c5087bba1d04eb6000115f0584141be258"
   },
   "source": [
    "## LightGBM\n",
    "\n",
    "Here I want to test [Oleg's Model Parameters](https://www.kaggle.com/opanichev/lightgbm-and-tf-idf-starter/code) on my data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "f2cbf632-72e0-40fc-8c89-221618546bbf",
    "_uuid": "ad18d28bfec4841c918d7a9510ed06fa8308055b",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'max_depth': 12,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.1, # Increased Learning Rate for now..\n",
    "    'feature_fraction': 0.85,\n",
    "    'bagging_fraction': 0.85,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'num_threads': 1,\n",
    "    'lambda_l2': 1,\n",
    "    'min_gain_to_split': 0,\n",
    "}  \n",
    "\n",
    "modelstart = time.time()\n",
    "lgb_clf = lgb.train(\n",
    "    lgbm_params,\n",
    "    lgb.Dataset(X_train, y_train, feature_name=tfvocab),\n",
    "    num_boost_round=400,\n",
    "    valid_sets=[lgb.Dataset(X_valid, y_valid)],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "f71be493-fd94-429a-9b3f-a56ba0696f08",
    "_uuid": "65471315b3947eb79d3f005bcf45210d85f001e0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbmpred = lgb_clf.predict(testing)\n",
    "lgbm_sub = pd.DataFrame(lgbmpred,columns=[\"project_is_approved\"],index=tesdex)\n",
    "lgbm_sub.to_csv(\"lgbm_sub.csv\",index=True)\n",
    "print(\"Model Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "3cb68647-c2ec-4ac1-99ce-b9a9f6466641",
    "_uuid": "0eea7a52689ad82dd8655e94345fce70f50e7cbd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=[7,10])\n",
    "lgb.plot_importance(lgb_clf, max_num_features=50, ax=ax)\n",
    "plt.title(\"Light GBM Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5548e10a-3185-4293-b688-b3a3721f1113",
    "_uuid": "efde865cac1f400d57f0bc78e83cc3feba7461e6"
   },
   "source": [
    "\n",
    "***\n",
    "*Simple Blend:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "c3444d36-966a-42c6-a866-9da6f06773aa",
    "_uuid": "bd8c2eb8110307ceb044cbc148cad962c6f229ae",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Model Correlation: \", pd.Series(lgbmpred).corr(pd.Series(xgb_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "062d68bc-fab6-4248-b3e3-f813848b5312",
    "_uuid": "9e3b180c5bbcd85db9878789bb1d3029b6bb67be",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blend = (lgbmpred*.5) + (xgb_pred*.5)\n",
    "blend_sub = pd.DataFrame(blend,columns=[\"project_is_approved\"],index=tesdex)\n",
    "blend_sub.to_csv(\"boost_blend_sub.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "949f7130-8fad-43f0-a78d-26a105690663",
    "_uuid": "aaea6782b9b6f49c538bc86bf9afaadeab88c2de",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concat_subs = pd.concat([lgbm_sub,xgb_sub,blend_sub], axis=1)\n",
    "concat_subs.columns = [\"LGBM\",\"XGB\",\"BLEND\"]\n",
    "concat_subs.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "36329bd6-1f28-4a1e-8840-dad0aefe101b",
    "_uuid": "e94af6f4d4cc577354122289d57dcee2f4941dde",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "607ec1c3-9170-4ced-82cf-aa6a55b17a1a",
    "_uuid": "b99f322a920f67c01d94e95780bc0ad92121903e",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
